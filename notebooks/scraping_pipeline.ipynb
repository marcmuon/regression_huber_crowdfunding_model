{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target & Feature Scrape Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6449,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from sklearn.linear_model import RidgeCV\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = ['retina']\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, HuberRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.gofplots import ProbPlot\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('figure', titlesize=18)\n",
    "plt.rc('axes', labelsize=15)\n",
    "plt.rc('axes', titlesize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/marcmuon/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/marcmuon/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Campaign Full Overview Text and Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def campaign_text():\n",
    "\n",
    "    # Grab description of campaign in text\n",
    "    words = soup.find(class_='full-description').text\n",
    "    words = words.replace('\\xa0', '').split('\\n')\n",
    "\n",
    "    # Count number of words in campaign description\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        sentence = word.split(' ')\n",
    "        count += len(sentence)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Campaign Summary and Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def campaign_text_len():\n",
    "\n",
    "    # Grab campaign title text\n",
    "    desc = soup.find(class_='type-18-md').text\n",
    "    desc_words = desc.split(' ')\n",
    "    return len(desc_words)\n",
    "    # title = soup.title.text\n",
    "    # title_txt = title.split('by')[0].strip()\n",
    "    # print(len(title_txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Suggested Pledge Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pledge_amount():\n",
    "\n",
    "    pledge = soup.input\n",
    "    pledge = str(soup.find(class_='pledge__no-reward__input'))\n",
    "    pledge_int = int(pledge.split('value=\"')[1][0:2])\n",
    "    return pledge_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Number of Images in Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_count():\n",
    "\n",
    "    images = soup.find_all(class_='fit')\n",
    "    return len(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Header or Not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_header():\n",
    "    header = soup.find_all(class_='ksr-video-player')\n",
    "    if header:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Pledged and Goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pledged_amount():\n",
    "    pledged = soup.find(class_='ksr-green-700').text\n",
    "    return pledged\n",
    "\n",
    "\n",
    "def goal_amount():\n",
    "    goal = soup.find(class_='money').text\n",
    "    return goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Number of Pledge Gift Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gift_options():\n",
    "\n",
    "    gifts = soup.find_all(class_='pledge__hover-content')\n",
    "    gift_num = len(gifts)\n",
    "    return gift_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Average Pledge Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pledge_amount():\n",
    "\n",
    "    convert = soup.find_all(class_='pledge__currency-conversion')\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for options in convert:\n",
    "        options = options.text\n",
    "        amount = options.split('$')[1].strip()\n",
    "        amount = amount.replace(',', '')\n",
    "        amount = amount.split('.')[0]\n",
    "        total += int(amount)\n",
    "        count += 1\n",
    "    average_option = total / count\n",
    "    return average_option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def description_sentiment():\n",
    "\n",
    "    # get sentiment of the description\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    words = soup.find(class_='full-description').text\n",
    "    words = words.replace('\\xa0', '').split('\\n')\n",
    "    chunk = ''\n",
    "    for word in words:\n",
    "        if word:\n",
    "            chunk = chunk + ' ' + word\n",
    "    scores = sid.polarity_scores(chunk)\n",
    "    return scores\n",
    "\n",
    "def sentiment_parse_pos(scores_dict):\n",
    "    return scores_dict['pos']\n",
    "\n",
    "def sentiment_parse_neg(scores_dict):\n",
    "    return scores_dict['neg']\n",
    "\n",
    "def sentiment_parse_neu(scores_dict):\n",
    "    return scores_dict['neu']\n",
    "\n",
    "def sentiment_parse_compound(scores_dict):\n",
    "    return scores_dict['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_sentiment():\n",
    "    desc = soup.find(class_='type-18-md').text\n",
    "    # get sentiment of the summary text\n",
    "    sid2 = SentimentIntensityAnalyzer()\n",
    "    scores_desc = sid2.polarity_scores(desc)\n",
    "    return scores_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Project Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_page(url):\n",
    "\n",
    "    update_page = '/updates'\n",
    "    url = url.split('?')[0]\n",
    "    updates = url + update_page\n",
    "    response = requests.get(updates)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "def project_length(url):\n",
    "    soup = update_page(url)\n",
    "    start = soup.find_all('time')\n",
    "    first = start[-1].text\n",
    "    now = datetime.datetime.now()\n",
    "    dt = parser.parse(first)\n",
    "    diff = now - dt\n",
    "    day_length = diff.days\n",
    "    return day_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline to Scrape All Pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect List of Pages to Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4694,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromedriver = \"/Applications/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "page = '1'\n",
    "url = 'https://www.kickstarter.com/discover/advanced?woe_id=23424977&sort=end_date&seed=2579760&page=' + page\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4695,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.kickstarter.com/projects/1819480674/makeup-and-cosmetics-self-love-brand?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/amberdunnministries/amber-dunn-worship-ep-heaven-reaching-down?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/206230260/derelict-ink-vol-2?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/threecupsdesign/make-100-sigils?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/1357652086/berashield-total-protection-system-for-smartphone?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/nickjcrabb/camber-brewing-company-help-us-make-the-best-beer?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/privateerpress/the-art-of-privateer-press?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/1789463192/extra-virgin-olive-oil-from-catalonia-spain?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/njpartistry/a-childs-artistry?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/outofmycomfortzone/out-of-my-comfort-zone-feature-film-musical-finish?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/1034323486/cambuddy-plus-your-cameras-wireless-gateway-to-the?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/229229006/the-folding-food-trays?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/1506870790/hash-cabbages-1st-record?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/1423402159/cosmic-cuties-enamel-pins?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/195555756/kettles-map?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/skellopia/biblical-babes-with-bad-advice-enamel-pins?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/486491295/razor-life-saver-lengthen-the-useful-life-of-your?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/1852466551/cuddly-and-stretchy-jumbo-anxiety-fox-plush?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/literarypins/literary-enamel-pins?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/1646137495/thego-pack-limited-team-editions?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/2113750962/rollin-travelers?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/1060215912/supplies-for-cake-designs?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/requiem/journey-augmented-reality-game-and-glasses?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/soulmegadc/soul-mega-production-and-distribution-campaign?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/1048567089/most-ardently-an-austen-inspired-christmas-collect-0?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/1040417273/custers-last-stand-the-little-big-horn-campaign?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/1166313109/nike-sneakers-customized-with-united-states-one-do?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/goodideascomics/energyman-a-super-hero-mystery-in-12-parts?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/magicmultiversity/the-magic-academy?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/2016091192/the-tide-a-kinetic-worry-coin?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/egjeans/eg-jeans-recycle-denim-material?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/braveent/nsights-first-album-release?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/713527201/the-black-and-white-collective?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/tsuluna/ditto-ice-cream-enamel-pins?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/1478299871/the-pink-elephant-independent-film-project?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/1765367532/make-100-thaumatrope-mecanique?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/159974695/make-100-enchanting-drawings?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/musicspace/open-the-music-space-of-owatonna-and-support-live?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/sethgadsden/custodian-custodio?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/2027539363/amelia-sky-issue-3-the-monster-within-tells-you?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/storybrookboutique/conversation-heart-pin-collection?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/fiends/fiends-buy-one-give-one-storybook?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/ruggedbank/pwr27-your-traveling-powerstation-charge-anything?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/familylegacybooks/custom-family-history-legacy-genealogy-books?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/909305351/jesus-today?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/carspa/carspa-vehicle-valet-service-for-routine-maintenan?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/796974130/mystery-babylon-fantasy-adventure-comic-omnibus-1?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/docoy/docoy-the-most-powerful-and-portable-projector?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/emmajaynefarkas/chasing-letters-a-student-film?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/501672592/a-good-death?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/lynnslogodesigns/pay-what-you-want-amazing-original-vector-logo-des?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/1694335676/project-dungeoneer?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/339943379/mephistopheles-0?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/lyricallids/lyrical-lids?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/aiitny/ifun-app-an-ai-lifestyle-management-system?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/217002756/the-dark-veil?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/208847477/outrage-movie-trailer?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/2140446742/restorative-kitchen-a-book-for-healing-and-optimal?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/music360/monica-brooks-audio-engineer?ref=discovery',\n",
       " 'https://www.kickstarter.com/projects/quepasausa/zombie-trump-monkey-smash?ref=discovery']"
      ]
     },
     "execution_count": 4695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_list = []\n",
    "for p in range(8, 13):\n",
    "    page = str(p)\n",
    "    \n",
    "    url = 'https://www.kickstarter.com/discover/advanced?woe_id=23424977&sort=end_date&seed=2579603&page=' + page\n",
    "    time.sleep(.1+.6*random.random())\n",
    "    driver.get(url)\n",
    "    elems = driver.find_elements_by_xpath(\"//a[@href and @class='block img-placeholder w100p']\")\n",
    "    for elem in elems:\n",
    "        link_list.append(elem.get_attribute(\"href\"))\n",
    "link_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Link List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4696,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('links_3day_3lt.pkl', 'wb') as f:\n",
    "    pickle.dump(link_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list = link_list[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape all Pages in Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4697,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n"
     ]
    }
   ],
   "source": [
    "df_dict = dict()\n",
    "row_list = []\n",
    "for idx, link in enumerate(link_list):\n",
    "    row_list = []\n",
    "    url = link\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    \n",
    "    #row_list.append(target())\n",
    "    row_list.append(pledged_amount())\n",
    "    row_list.append(goal_amount())\n",
    "    row_list.append(campaign_text())\n",
    "    row_list.append(campaign_text_len())\n",
    "    row_list.append(pledge_amount())\n",
    "    row_list.append(image_count())\n",
    "    row_list.append(video_header())\n",
    "    row_list.append(gift_options())\n",
    "    row_list.append(average_pledge_amount())\n",
    "    \n",
    "    overview_scores = description_sentiment()\n",
    "    row_list.append(sentiment_parse_pos(overview_scores))\n",
    "    row_list.append(sentiment_parse_neg(overview_scores))\n",
    "    row_list.append(sentiment_parse_neu(overview_scores))\n",
    "    row_list.append(sentiment_parse_compound(overview_scores))\n",
    "    \n",
    "    summary_scores = summary_sentiment()\n",
    "    row_list.append(sentiment_parse_pos(summary_scores))\n",
    "    row_list.append(sentiment_parse_neg(summary_scores))\n",
    "    row_list.append(sentiment_parse_neu(summary_scores))\n",
    "    row_list.append(sentiment_parse_compound(summary_scores))\n",
    "    \n",
    "    row_list.append(project_length(url))\n",
    "    df_dict[idx]= row_list\n",
    "    print(idx)\n",
    "    time.sleep(.1+.6*random.random())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Scraped Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4698,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('dict_3day_3lt.pkl', 'wb') as f:\n",
    "    pickle.dump(df_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
